Meta VERSION="1" .
Job JOBID="job_201508232259_0007" JOBNAME="hadoop-streaming\.jar" USER="vagrant" SUBMIT_TIME="1440381323946" JOBCONF="hdfs://vm-cluster-client:8020/user/vagrant/\.staging/job_201508232259_0007/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201508232259_0007" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201508232259_0007" LAUNCH_TIME="1440381324216" TOTAL_MAPS="22" TOTAL_REDUCES="3" JOB_STATUS="PREP" .
Task TASKID="task_201508232259_0007_m_000023" TASK_TYPE="SETUP" START_TIME="1440381324217" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201508232259_0007_m_000023" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000023_0" START_TIME="1440381324467" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201508232259_0007_m_000023" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000023_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440381326230" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171605)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(100630528)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(871309312)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40173568)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000023" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1440381326368" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171605)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(100630528)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(871309312)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40173568)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201508232259_0007" JOB_STATUS="RUNNING" .
Task TASKID="task_201508232259_0007_m_000001" TASK_TYPE="MAP" START_TIME="1440381327009" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0007_m_000002" TASK_TYPE="MAP" START_TIME="1440381327011" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0007_m_000004" TASK_TYPE="MAP" START_TIME="1440381327240" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node4" .
Task TASKID="task_201508232259_0007_m_000006" TASK_TYPE="MAP" START_TIME="1440381327241" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node3,/default/vm-cluster-node4" .
Task TASKID="task_201508232259_0007_m_000000" TASK_TYPE="MAP" START_TIME="1440381327276" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0007_m_000003" TASK_TYPE="MAP" START_TIME="1440381327280" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0007_m_000005" TASK_TYPE="MAP" START_TIME="1440381327281" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0007_m_000007" TASK_TYPE="MAP" START_TIME="1440381327288" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0007_m_000011" TASK_TYPE="MAP" START_TIME="1440381327290" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0007_m_000012" TASK_TYPE="MAP" START_TIME="1440381327291" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node2" .
Task TASKID="task_201508232259_0007_m_000009" TASK_TYPE="MAP" START_TIME="1440381327292" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node5" .
Task TASKID="task_201508232259_0007_m_000010" TASK_TYPE="MAP" START_TIME="1440381327293" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000002" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000002_0" START_TIME="1440381327039" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000002" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383108235" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1107966/36192" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(574689)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113365)][(MAP_OUTPUT_RECORDS)(Map output records)(36393)][(MAP_OUTPUT_BYTES)(Map output bytes)(680771)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1593460)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149975040)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889237504)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217691)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383108395" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(574689)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113365)][(MAP_OUTPUT_RECORDS)(Map output records)(36393)][(MAP_OUTPUT_BYTES)(Map output bytes)(680771)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1593460)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149975040)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889237504)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217691)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000013" TASK_TYPE="MAP" START_TIME="1440383108404" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000012" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000012_0" START_TIME="1440381327587" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000012" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383114096" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1110706/36075" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572243)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113974)][(MAP_OUTPUT_RECORDS)(Map output records)(36231)][(MAP_OUTPUT_BYTES)(Map output bytes)(677874)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36231)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1593140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(146853888)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879329280)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217681)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383114274" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572243)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113974)][(MAP_OUTPUT_RECORDS)(Map output records)(36231)][(MAP_OUTPUT_BYTES)(Map output bytes)(677874)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36231)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1593140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(146853888)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879329280)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217681)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000015" TASK_TYPE="MAP" START_TIME="1440383114304" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000001" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000001_0" START_TIME="1440381327038" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000001" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383126928" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1111450/35546" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563893)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113636)][(MAP_OUTPUT_RECORDS)(Map output records)(35632)][(MAP_OUTPUT_BYTES)(Map output bytes)(665844)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35632)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1599490)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(143597568)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879247360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217828)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383127228" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563893)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113636)][(MAP_OUTPUT_RECORDS)(Map output records)(35632)][(MAP_OUTPUT_BYTES)(Map output bytes)(665844)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35632)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1599490)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(143597568)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879247360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217828)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000016" TASK_TYPE="MAP" START_TIME="1440383127234" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000010" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000010_0" START_TIME="1440381327628" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000010" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383131886" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1112165/35466" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563492)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114290)][(MAP_OUTPUT_RECORDS)(Map output records)(35557)][(MAP_OUTPUT_BYTES)(Map output bytes)(664423)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35557)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1604620)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145620992)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(887635968)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217822)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383131935" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563492)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114290)][(MAP_OUTPUT_RECORDS)(Map output records)(35557)][(MAP_OUTPUT_BYTES)(Map output bytes)(664423)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35557)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1604620)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145620992)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(887635968)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217822)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000018" TASK_TYPE="MAP" START_TIME="1440383131993" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node4" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000004" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000004_0" START_TIME="1440381327452" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000004" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383135172" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1109226/35918" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571555)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113508)][(MAP_OUTPUT_RECORDS)(Map output records)(36143)][(MAP_OUTPUT_BYTES)(Map output bytes)(676217)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36143)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1606500)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(151183360)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885297152)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217748)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383135345" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571555)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113508)][(MAP_OUTPUT_RECORDS)(Map output records)(36143)][(MAP_OUTPUT_BYTES)(Map output bytes)(676217)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36143)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1606500)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(151183360)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885297152)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217748)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000008" TASK_TYPE="MAP" START_TIME="1440383135409" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node4" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000006" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000006_0" START_TIME="1440381327460" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000006" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383135388" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1110660/35839" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(569319)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113943)][(MAP_OUTPUT_RECORDS)(Map output records)(35987)][(MAP_OUTPUT_BYTES)(Map output bytes)(672810)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35987)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1627120)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137416704)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881000448)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217690)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383135732" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(569319)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113943)][(MAP_OUTPUT_RECORDS)(Map output records)(35987)][(MAP_OUTPUT_BYTES)(Map output bytes)(672810)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35987)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1627120)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137416704)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881000448)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217690)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000014" TASK_TYPE="MAP" START_TIME="1440383135776" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000011" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000011_0" START_TIME="1440381327581" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000011" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383141969" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1109850/36180" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572289)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113070)][(MAP_OUTPUT_RECORDS)(Map output records)(36365)][(MAP_OUTPUT_BYTES)(Map output bytes)(679636)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36365)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1621330)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(153321472)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889311232)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217680)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383142242" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572289)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113070)][(MAP_OUTPUT_RECORDS)(Map output records)(36365)][(MAP_OUTPUT_BYTES)(Map output bytes)(679636)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36365)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1621330)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(153321472)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889311232)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217680)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000021" TASK_TYPE="MAP" START_TIME="1440383142288" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000009" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000009_0" START_TIME="1440381327627" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000009" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383156695" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1108668/36533" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(577555)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114105)][(MAP_OUTPUT_RECORDS)(Map output records)(36684)][(MAP_OUTPUT_BYTES)(Map output bytes)(686696)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36684)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1621290)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137482240)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878596096)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217641)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383156866" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(577555)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114105)][(MAP_OUTPUT_RECORDS)(Map output records)(36684)][(MAP_OUTPUT_BYTES)(Map output bytes)(686696)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36684)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1621290)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137482240)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878596096)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217641)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000019" TASK_TYPE="MAP" START_TIME="1440383156873" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node5" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000007" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000007_0" START_TIME="1440381327372" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000007" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383170731" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1112481/35821" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(567740)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113531)][(MAP_OUTPUT_RECORDS)(Map output records)(35890)][(MAP_OUTPUT_BYTES)(Map output bytes)(670711)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35890)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1573550)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(147595264)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889618432)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71106560)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217686)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383170895" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(567740)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113531)][(MAP_OUTPUT_RECORDS)(Map output records)(35890)][(MAP_OUTPUT_BYTES)(Map output bytes)(670711)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35890)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1573550)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(147595264)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889618432)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71106560)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217686)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000017" TASK_TYPE="MAP" START_TIME="1440383170921" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000005" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000005_0" START_TIME="1440381327370" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000005" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383219741" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1112003/35904" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(569440)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113079)][(MAP_OUTPUT_RECORDS)(Map output records)(35971)][(MAP_OUTPUT_BYTES)(Map output bytes)(672862)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35971)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1597330)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145756160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879079424)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217752)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383220022" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(569440)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113079)][(MAP_OUTPUT_RECORDS)(Map output records)(35971)][(MAP_OUTPUT_BYTES)(Map output bytes)(672862)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35971)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1597330)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145756160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879079424)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217752)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000020" TASK_TYPE="MAP" START_TIME="1440383224726" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node3,/default/vm-cluster-node5" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000000" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000000_0" START_TIME="1440381327676" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000000" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383380920" HOSTNAME="/default/vm-cluster-client" STATE_STRING="Records R/W\=1110723/35948" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(570463)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113973)][(MAP_OUTPUT_RECORDS)(Map output records)(36135)][(MAP_OUTPUT_BYTES)(Map output bytes)(675520)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36135)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1637350)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137744384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885714944)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217729)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383380938" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(570463)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113973)][(MAP_OUTPUT_RECORDS)(Map output records)(36135)][(MAP_OUTPUT_BYTES)(Map output bytes)(675520)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36135)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1637350)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137744384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885714944)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217729)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000003" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000003_0" START_TIME="1440381327682" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000003" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383396195" HOSTNAME="/default/vm-cluster-client" STATE_STRING="Records R/W\=1111495/36371" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(574865)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113660)][(MAP_OUTPUT_RECORDS)(Map output records)(36466)][(MAP_OUTPUT_BYTES)(Map output bytes)(682286)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36466)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1635410)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(122650624)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881201152)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217702)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383396456" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(574865)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113660)][(MAP_OUTPUT_RECORDS)(Map output records)(36466)][(MAP_OUTPUT_BYTES)(Map output bytes)(682286)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36466)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1635410)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(122650624)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881201152)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217702)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000021" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000021_0" START_TIME="1440383142304" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000021" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440383523385" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=255277/7896" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(264867)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(31408465)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(260461)][(MAP_OUTPUT_RECORDS)(Map output records)(8070)][(MAP_OUTPUT_BYTES)(Map output bytes)(150709)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8070)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(350600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(162758656)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880001024)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(87556096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(31408278)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000021" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440383523536" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(264867)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(31408465)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(260461)][(MAP_OUTPUT_RECORDS)(Map output records)(8070)][(MAP_OUTPUT_BYTES)(Map output bytes)(150709)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8070)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(350600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(162758656)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880001024)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(87556096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(31408278)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000015" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000015_0" START_TIME="1440383114318" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000015" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384505989" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1114700/35390" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563077)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114700)][(MAP_OUTPUT_RECORDS)(Map output records)(35407)][(MAP_OUTPUT_BYTES)(Map output bytes)(662031)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35407)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1361230)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(130879488)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880377856)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217767)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384506110" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(563077)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114700)][(MAP_OUTPUT_RECORDS)(Map output records)(35407)][(MAP_OUTPUT_BYTES)(Map output bytes)(662031)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35407)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1361230)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(130879488)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880377856)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217767)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000016" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000016_0" START_TIME="1440383127211" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000016" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384529527" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1107787/35269" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(564291)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114360)][(MAP_OUTPUT_RECORDS)(Map output records)(35511)][(MAP_OUTPUT_BYTES)(Map output bytes)(663792)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35511)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1310610)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(150781952)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879079424)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217663)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384529903" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(564291)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114360)][(MAP_OUTPUT_RECORDS)(Map output records)(35511)][(MAP_OUTPUT_BYTES)(Map output bytes)(663792)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35511)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1310610)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(150781952)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879079424)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217663)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000013" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000013_0" START_TIME="1440383108394" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000013" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384532016" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1113054/36284" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(573144)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114082)][(MAP_OUTPUT_RECORDS)(Map output records)(36349)][(MAP_OUTPUT_BYTES)(Map output bytes)(679462)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36349)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1333740)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(136949760)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877936640)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217738)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384532333" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(573144)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114082)][(MAP_OUTPUT_RECORDS)(Map output records)(36349)][(MAP_OUTPUT_BYTES)(Map output bytes)(679462)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36349)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1333740)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(136949760)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877936640)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217738)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000008" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000008_0" START_TIME="1440383135421" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000008" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384540998" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1111633/36164" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113778)][(MAP_OUTPUT_RECORDS)(Map output records)(36236)][(MAP_OUTPUT_BYTES)(Map output bytes)(677630)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36236)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1307090)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142471168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881135616)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217826)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384541108" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113778)][(MAP_OUTPUT_RECORDS)(Map output records)(36236)][(MAP_OUTPUT_BYTES)(Map output bytes)(677630)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36236)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1307090)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142471168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881135616)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217826)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000014" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000014_0" START_TIME="1440383135797" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000014" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384554580" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1105234/35438" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(566322)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112908)][(MAP_OUTPUT_RECORDS)(Map output records)(35769)][(MAP_OUTPUT_BYTES)(Map output bytes)(668726)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35769)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1324150)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148148224)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(888901632)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217739)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384554740" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(566322)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112908)][(MAP_OUTPUT_RECORDS)(Map output records)(35769)][(MAP_OUTPUT_BYTES)(Map output bytes)(668726)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35769)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1324150)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148148224)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(888901632)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217739)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_r_000000" TASK_TYPE="REDUCE" START_TIME="1440384555320" SPLITS="" .
Task TASKID="task_201508232259_0007_r_000001" TASK_TYPE="REDUCE" START_TIME="1440384555350" SPLITS="" .
Task TASKID="task_201508232259_0007_r_000002" TASK_TYPE="REDUCE" START_TIME="1440384555352" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000018" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000018_0" START_TIME="1440383132007" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000018" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384566409" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1108641/35596" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(566880)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112967)][(MAP_OUTPUT_RECORDS)(Map output records)(35768)][(MAP_OUTPUT_BYTES)(Map output bytes)(669038)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35768)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1333230)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137596928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881336320)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217725)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384566563" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(566880)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112967)][(MAP_OUTPUT_RECORDS)(Map output records)(35768)][(MAP_OUTPUT_BYTES)(Map output bytes)(669038)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35768)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1333230)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137596928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881336320)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217725)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000019" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000019_0" START_TIME="1440383156886" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000019" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384568726" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1107689/36026" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(573929)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114237)][(MAP_OUTPUT_RECORDS)(Map output records)(36362)][(MAP_OUTPUT_BYTES)(Map output bytes)(680426)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36362)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1311960)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138825728)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880623616)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217685)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384568986" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(573929)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114237)][(MAP_OUTPUT_RECORDS)(Map output records)(36362)][(MAP_OUTPUT_BYTES)(Map output bytes)(680426)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36362)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1311960)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138825728)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880623616)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217685)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000017" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000017_0" START_TIME="1440383170927" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000017" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384599182" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1101559/35777" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571894)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114728)][(MAP_OUTPUT_RECORDS)(Map output records)(36303)][(MAP_OUTPUT_BYTES)(Map output bytes)(678452)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36303)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1291280)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(147472384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889729024)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217770)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384599389" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(571894)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114728)][(MAP_OUTPUT_RECORDS)(Map output records)(36303)][(MAP_OUTPUT_BYTES)(Map output bytes)(678452)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36303)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1291280)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(147472384)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889729024)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217770)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000020" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000020_0" START_TIME="1440383224742" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0007_m_000020" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384611721" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1097613/35716" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572623)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114166)][(MAP_OUTPUT_RECORDS)(Map output records)(36292)][(MAP_OUTPUT_BYTES)(Map output bytes)(678722)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36292)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1260800)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(150609920)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(891404288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(74448896)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217802)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000020" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384611824" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(572623)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114166)][(MAP_OUTPUT_RECORDS)(Map output records)(36292)][(MAP_OUTPUT_BYTES)(Map output bytes)(678722)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36292)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1260800)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(150609920)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(891404288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(74448896)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217802)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000002" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000002_0" START_TIME="1440384555338" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000002" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000002_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440384612847" SORT_FINISHED="1440384613044" FINISH_TIME="1440384621267" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=217011/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2316188)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(2487502)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(985)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(37)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2394358)][(REDUCE_INPUT_RECORDS)(Reduce input records)(217011)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(37)][(SPILLED_RECORDS)(Spilled Records)(217011)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8900)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(131878912)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(899182592)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(51052544)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_r_000002" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440384621410" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2316188)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(2487502)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(985)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(37)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2394358)][(REDUCE_INPUT_RECORDS)(Reduce input records)(217011)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(37)][(SPILLED_RECORDS)(Spilled Records)(217011)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8900)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(131878912)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(899182592)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(51052544)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000001" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000001_0" START_TIME="1440384555329" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000001" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000001_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440384611959" SORT_FINISHED="1440384612165" FINISH_TIME="1440384621966" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=258117/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2742912)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(2914228)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1158)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2847050)][(REDUCE_INPUT_RECORDS)(Reduce input records)(258117)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42)][(SPILLED_RECORDS)(Spilled Records)(258117)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(10720)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(135581696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889913344)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(43515904)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_r_000001" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440384622267" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2742912)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(2914228)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1158)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(2847050)][(REDUCE_INPUT_RECORDS)(Reduce input records)(258117)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(42)][(SPILLED_RECORDS)(Spilled Records)(258117)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(10720)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(135581696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(889913344)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(43515904)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000000" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000000_0" START_TIME="1440384555220" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0007_r_000000" TASK_ATTEMPT_ID="attempt_201508232259_0007_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440384611885" SORT_FINISHED="1440384612101" FINISH_TIME="1440384622541" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=290393/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(3117827)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3289141)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1046)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(38)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3217741)][(REDUCE_INPUT_RECORDS)(Reduce input records)(290393)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(38)][(SPILLED_RECORDS)(Spilled Records)(290393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(9370)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(146145280)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(892321792)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(47054848)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440384622871" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(3117827)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3289141)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1046)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(38)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3217741)][(REDUCE_INPUT_RECORDS)(Reduce input records)(290393)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(38)][(SPILLED_RECORDS)(Spilled Records)(290393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(9370)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(146145280)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(892321792)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(47054848)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000022" TASK_TYPE="CLEANUP" START_TIME="1440384622873" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201508232259_0007_m_000022" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000022_0" START_TIME="1440384622773" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201508232259_0007_m_000022" TASK_ATTEMPT_ID="attempt_201508232259_0007_m_000022_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440384624505" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171605)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(106233856)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880238592)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40435712)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0007_m_000022" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1440384624693" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171605)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(90)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(106233856)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880238592)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40435712)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201508232259_0007" FINISH_TIME="1440384624694" JOB_STATUS="SUCCESS" FINISHED_MAPS="22" FINISHED_REDUCES="3" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(12236219)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2851359319)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(44)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(23650521)][(MAP_OUTPUT_RECORDS)(Map output records)(765521)][(MAP_OUTPUT_BYTES)(Map output bytes)(14314638)][(SPLIT_RAW_BYTES)(Input split bytes)(2420)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(765521)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(31495280)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(3165691904)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(19435794432)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1587544064)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(2849980643)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(8176927)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(8690871)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3189)][(HDFS_READ_OPS)(HDFS: Number of read operations)(4)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(6)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(117)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(8459149)][(REDUCE_INPUT_RECORDS)(Reduce input records)(765521)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(117)][(SPILLED_RECORDS)(Spilled Records)(765521)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(28990)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(413605888)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(2681417728)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(141623296)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(8176927)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(20927090)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2851359319)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3189)][(HDFS_READ_OPS)(HDFS: Number of read operations)(48)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(6)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(22)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(3)][(DATA_LOCAL_MAPS)(Data-local map tasks)(21)][(RACK_LOCAL_MAPS)(Rack-local map tasks)(1)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(35376465)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(199887)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(23650521)][(MAP_OUTPUT_RECORDS)(Map output records)(765521)][(MAP_OUTPUT_BYTES)(Map output bytes)(14314638)][(SPLIT_RAW_BYTES)(Input split bytes)(2420)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(117)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(8459149)][(REDUCE_INPUT_RECORDS)(Reduce input records)(765521)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(117)][(SPILLED_RECORDS)(Spilled Records)(1531042)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(31524270)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(3579297792)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(22117212160)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1729167360)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(2849980643)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
