Meta VERSION="1" .
Job JOBID="job_201508232259_0009" JOBNAME="hadoop-streaming\.jar" USER="vagrant" SUBMIT_TIME="1440388461915" JOBCONF="hdfs://vm-cluster-client:8020/user/vagrant/\.staging/job_201508232259_0009/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201508232259_0009" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201508232259_0009" LAUNCH_TIME="1440388462184" TOTAL_MAPS="22" TOTAL_REDUCES="3" JOB_STATUS="PREP" .
Task TASKID="task_201508232259_0009_m_000023" TASK_TYPE="SETUP" START_TIME="1440388462185" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201508232259_0009_m_000023" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000023_0" START_TIME="1440388463556" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201508232259_0009_m_000023" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000023_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440388465281" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171626)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(70)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(101236736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(866263040)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40370176)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000023" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1440388464316" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171626)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(70)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(101236736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(866263040)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40370176)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201508232259_0009" JOB_STATUS="RUNNING" .
Task TASKID="task_201508232259_0009_m_000001" TASK_TYPE="MAP" START_TIME="1440388466116" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0009_m_000002" TASK_TYPE="MAP" START_TIME="1440388466118" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0009_m_000000" TASK_TYPE="MAP" START_TIME="1440388466135" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0009_m_000003" TASK_TYPE="MAP" START_TIME="1440388466137" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0009_m_000004" TASK_TYPE="MAP" START_TIME="1440388466151" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node4" .
Task TASKID="task_201508232259_0009_m_000005" TASK_TYPE="MAP" START_TIME="1440388466151" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node1" .
Task TASKID="task_201508232259_0009_m_000011" TASK_TYPE="MAP" START_TIME="1440388466185" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0009_m_000012" TASK_TYPE="MAP" START_TIME="1440388466186" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node2" .
Task TASKID="task_201508232259_0009_m_000006" TASK_TYPE="MAP" START_TIME="1440388466233" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node3,/default/vm-cluster-node4" .
Task TASKID="task_201508232259_0009_m_000007" TASK_TYPE="MAP" START_TIME="1440388466233" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node3" .
Task TASKID="task_201508232259_0009_m_000008" TASK_TYPE="MAP" START_TIME="1440388466251" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node4" .
Task TASKID="task_201508232259_0009_m_000009" TASK_TYPE="MAP" START_TIME="1440388466252" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node5" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000011" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000011_0" START_TIME="1440388488497" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000011" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390245625" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1113070/36349" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640941)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113070)][(MAP_OUTPUT_RECORDS)(Map output records)(36365)][(MAP_OUTPUT_BYTES)(Map output bytes)(1230482)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36365)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585780)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148836352)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890540032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217680)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390245855" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640941)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113070)][(MAP_OUTPUT_RECORDS)(Map output records)(36365)][(MAP_OUTPUT_BYTES)(Map output bytes)(1230482)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36365)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585780)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148836352)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890540032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217680)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000013" TASK_TYPE="MAP" START_TIME="1440390245880" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000007" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000007_0" START_TIME="1440388488510" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000007" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390254349" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1113531/35864" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(636107)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113531)][(MAP_OUTPUT_RECORDS)(Map output records)(35890)][(MAP_OUTPUT_BYTES)(Map output bytes)(1214551)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35890)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1575490)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144203776)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881741824)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217686)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390254493" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(636107)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113531)][(MAP_OUTPUT_RECORDS)(Map output records)(35890)][(MAP_OUTPUT_BYTES)(Map output bytes)(1214551)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35890)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1575490)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144203776)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881741824)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217686)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000010" TASK_TYPE="MAP" START_TIME="1440390254522" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000012" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000012_0" START_TIME="1440388488500" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000012" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390257743" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1113974/36221" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(641600)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113974)][(MAP_OUTPUT_RECORDS)(Map output records)(36231)][(MAP_OUTPUT_BYTES)(Map output bytes)(1227130)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36231)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139481088)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878768128)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217681)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390257948" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(641600)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113974)][(MAP_OUTPUT_RECORDS)(Map output records)(36231)][(MAP_OUTPUT_BYTES)(Map output bytes)(1227130)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36231)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139481088)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878768128)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217681)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000015" TASK_TYPE="MAP" START_TIME="1440390257982" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000002" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000002_0" START_TIME="1440388466243" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000002" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390259785" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1113365/36377" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(643798)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113365)][(MAP_OUTPUT_RECORDS)(Map output records)(36393)][(MAP_OUTPUT_BYTES)(Map output bytes)(1232362)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1574650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138919936)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881074176)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217691)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390260012" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(643798)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113365)][(MAP_OUTPUT_RECORDS)(Map output records)(36393)][(MAP_OUTPUT_BYTES)(Map output bytes)(1232362)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36393)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1574650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138919936)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881074176)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217691)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000018" TASK_TYPE="MAP" START_TIME="1440390260026" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node5,/default/vm-cluster-node4" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000008" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000008_0" START_TIME="1440388488519" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000008" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390265373" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1113778/36188" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640762)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113778)][(MAP_OUTPUT_RECORDS)(Map output records)(36236)][(MAP_OUTPUT_BYTES)(Map output bytes)(1226700)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36236)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1582860)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(141832192)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882233344)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217826)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390265238" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640762)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113778)][(MAP_OUTPUT_RECORDS)(Map output records)(36236)][(MAP_OUTPUT_BYTES)(Map output bytes)(1226700)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36236)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1582860)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(141832192)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882233344)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217826)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000014" TASK_TYPE="MAP" START_TIME="1440390265240" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000006" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000006_0" START_TIME="1440388488508" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000006" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390269547" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1113943/35930" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(637643)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113943)][(MAP_OUTPUT_RECORDS)(Map output records)(35987)][(MAP_OUTPUT_BYTES)(Map output bytes)(1218664)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35987)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1607140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(151375872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(884539392)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217690)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390269707" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(637643)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113943)][(MAP_OUTPUT_RECORDS)(Map output records)(35987)][(MAP_OUTPUT_BYTES)(Map output bytes)(1218664)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35987)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1607140)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(151375872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(884539392)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217690)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000016" TASK_TYPE="MAP" START_TIME="1440390269731" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node3" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000009" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000009_0" START_TIME="1440388488520" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000009" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390276907" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1114105/36660" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(647462)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114105)][(MAP_OUTPUT_RECORDS)(Map output records)(36684)][(MAP_OUTPUT_BYTES)(Map output bytes)(1242635)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36684)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1601290)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137891840)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878682112)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217641)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390276791" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(647462)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114105)][(MAP_OUTPUT_RECORDS)(Map output records)(36684)][(MAP_OUTPUT_BYTES)(Map output bytes)(1242635)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36684)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1601290)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137891840)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878682112)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217641)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000017" TASK_TYPE="MAP" START_TIME="1440390276883" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node4,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000001" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000001_0" START_TIME="1440388466243" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000001" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390284400" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1113636/35619" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(633368)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113636)][(MAP_OUTPUT_RECORDS)(Map output records)(35632)][(MAP_OUTPUT_BYTES)(Map output bytes)(1206234)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35632)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1616690)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142893056)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882032640)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217828)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390284526" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(633368)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113636)][(MAP_OUTPUT_RECORDS)(Map output records)(35632)][(MAP_OUTPUT_BYTES)(Map output bytes)(1206234)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35632)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1616690)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142893056)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882032640)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217828)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000019" TASK_TYPE="MAP" START_TIME="1440390284528" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node1,/default/vm-cluster-node5" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000000" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000000_0" START_TIME="1440388467379" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000000" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390299047" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1111819/35985" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(639263)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113973)][(MAP_OUTPUT_RECORDS)(Map output records)(36135)][(MAP_OUTPUT_BYTES)(Map output bytes)(1222614)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36135)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585360)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139317248)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879845376)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217729)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390318660" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(639263)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113973)][(MAP_OUTPUT_RECORDS)(Map output records)(36135)][(MAP_OUTPUT_BYTES)(Map output bytes)(1222614)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36135)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1585360)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139317248)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879845376)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217729)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000021" TASK_TYPE="MAP" START_TIME="1440390318662" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node2,/default/vm-cluster-node1" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000003" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000003_0" START_TIME="1440388467380" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000003" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390328420" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1111495/36357" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(644241)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113660)][(MAP_OUTPUT_RECORDS)(Map output records)(36466)][(MAP_OUTPUT_BYTES)(Map output bytes)(1235282)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36466)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1583980)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138649600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877932544)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217702)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390347994" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(644241)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113660)][(MAP_OUTPUT_RECORDS)(Map output records)(36466)][(MAP_OUTPUT_BYTES)(Map output bytes)(1235282)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36466)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1583980)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(138649600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877932544)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71237632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217702)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000020" TASK_TYPE="MAP" START_TIME="1440390348935" SPLITS="/default/vm-cluster-client,/default/vm-cluster-node3,/default/vm-cluster-node5" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000004" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000004_0" START_TIME="1440388466307" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000004" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390523198" HOSTNAME="/default/vm-cluster-client" STATE_STRING="Records R/W\=1111385/36002" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(639978)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(3)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113508)][(MAP_OUTPUT_RECORDS)(Map output records)(36143)][(MAP_OUTPUT_BYTES)(Map output bytes)(1224259)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36143)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1615040)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(129486848)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882831360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217748)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390523323" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(639978)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(3)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113508)][(MAP_OUTPUT_RECORDS)(Map output records)(36143)][(MAP_OUTPUT_BYTES)(Map output bytes)(1224259)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36143)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1615040)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(129486848)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882831360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217748)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000005" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000005_0" START_TIME="1440388466309" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000005" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390543400" HOSTNAME="/default/vm-cluster-client" STATE_STRING="Records R/W\=1109820/35830" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(637548)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113079)][(MAP_OUTPUT_RECORDS)(Map output records)(35971)][(MAP_OUTPUT_BYTES)(Map output bytes)(1217587)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35971)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1626260)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(124190720)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882438144)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217752)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390543669" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(637548)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1113079)][(MAP_OUTPUT_RECORDS)(Map output records)(35971)][(MAP_OUTPUT_BYTES)(Map output bytes)(1217587)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35971)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1626260)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(124190720)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(882438144)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217752)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000021" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000021_0" START_TIME="1440390299272" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000021" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440390701139" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=255277/7915" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(286792)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(31408465)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(260461)][(MAP_OUTPUT_RECORDS)(Map output records)(8070)][(MAP_OUTPUT_BYTES)(Map output bytes)(273166)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8070)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(350060)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149831680)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(883060736)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(79429632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(31408278)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000021" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440390720423" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(286792)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(31408465)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(260461)][(MAP_OUTPUT_RECORDS)(Map output records)(8070)][(MAP_OUTPUT_BYTES)(Map output bytes)(273166)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8070)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(350060)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149831680)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(883060736)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(79429632)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(31408278)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000015" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000015_0" START_TIME="1440390258001" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000015" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391661810" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1113658/35330" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(630157)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114700)][(MAP_OUTPUT_RECORDS)(Map output records)(35407)][(MAP_OUTPUT_BYTES)(Map output bytes)(1198520)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35407)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1312100)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139456512)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881696768)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217767)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391661855" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(630157)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114700)][(MAP_OUTPUT_RECORDS)(Map output records)(35407)][(MAP_OUTPUT_BYTES)(Map output bytes)(1198520)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35407)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1312100)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(139456512)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881696768)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217767)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000010" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000010_0" START_TIME="1440390254452" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000010" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391671672" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1111083/35419" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(631791)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114290)][(MAP_OUTPUT_RECORDS)(Map output records)(35557)][(MAP_OUTPUT_BYTES)(Map output bytes)(1203085)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35557)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1322430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144797696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879861760)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217822)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391671995" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(631791)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114290)][(MAP_OUTPUT_RECORDS)(Map output records)(35557)][(MAP_OUTPUT_BYTES)(Map output bytes)(1203085)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35557)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1322430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144797696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879861760)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217822)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000013" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000013_0" START_TIME="1440390245901" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000013" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391676046" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=1105350/35950" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640993)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114082)][(MAP_OUTPUT_RECORDS)(Map output records)(36349)][(MAP_OUTPUT_BYTES)(Map output bytes)(1229782)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36349)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1341600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(143360000)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880201728)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217738)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391676172" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640993)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114082)][(MAP_OUTPUT_RECORDS)(Map output records)(36349)][(MAP_OUTPUT_BYTES)(Map output bytes)(1229782)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36349)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1341600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(143360000)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(880201728)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217738)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000018" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000018_0" START_TIME="1440390260018" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000018" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391680132" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1112967/35748" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(634310)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112967)][(MAP_OUTPUT_RECORDS)(Map output records)(35768)][(MAP_OUTPUT_BYTES)(Map output bytes)(1211217)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35768)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1332920)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(133677056)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881836032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217725)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391680451" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(634310)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112967)][(MAP_OUTPUT_RECORDS)(Map output records)(35768)][(MAP_OUTPUT_BYTES)(Map output bytes)(1211217)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35768)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1332920)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(133677056)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(881836032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217725)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000017" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000017_0" START_TIME="1440390277064" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000017" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391684623" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1104875/35879" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(641071)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(3)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114728)][(MAP_OUTPUT_RECORDS)(Map output records)(36303)][(MAP_OUTPUT_BYTES)(Map output bytes)(1228541)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36303)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1314960)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149852160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885116928)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217770)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391684768" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(641071)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(3)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114728)][(MAP_OUTPUT_RECORDS)(Map output records)(36303)][(MAP_OUTPUT_BYTES)(Map output bytes)(1228541)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36303)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1314960)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(149852160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(885116928)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217770)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000016" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000016_0" START_TIME="1440390269665" TRACKER_NAME="tracker_vm-cluster-node3:localhost/127\.0\.0\.1:38266" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000016" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391685071" HOSTNAME="/default/vm-cluster-node3" STATE_STRING="Records R/W\=1108887/35332" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(631664)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114360)][(MAP_OUTPUT_RECORDS)(Map output records)(35511)][(MAP_OUTPUT_BYTES)(Map output bytes)(1201904)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35511)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1320690)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148930560)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890548224)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217663)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391685352" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(631664)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114360)][(MAP_OUTPUT_RECORDS)(Map output records)(35511)][(MAP_OUTPUT_BYTES)(Map output bytes)(1201904)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35511)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1320690)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(148930560)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890548224)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217663)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000014" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000014_0" START_TIME="1440390265411" TRACKER_NAME="tracker_vm-cluster-node4:localhost/127\.0\.0\.1:55068" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000014" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391685289" HOSTNAME="/default/vm-cluster-node4" STATE_STRING="Records R/W\=1112908/35743" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(634533)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112908)][(MAP_OUTPUT_RECORDS)(Map output records)(35769)][(MAP_OUTPUT_BYTES)(Map output bytes)(1210285)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35769)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1314480)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(132403200)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877854720)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217739)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391685377" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(634533)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1112908)][(MAP_OUTPUT_RECORDS)(Map output records)(35769)][(MAP_OUTPUT_BYTES)(Map output bytes)(1210285)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(35769)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1314480)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(132403200)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(877854720)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217739)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_r_000000" TASK_TYPE="REDUCE" START_TIME="1440391685566" SPLITS="" .
Task TASKID="task_201508232259_0009_r_000001" TASK_TYPE="REDUCE" START_TIME="1440391685585" SPLITS="" .
Task TASKID="task_201508232259_0009_r_000002" TASK_TYPE="REDUCE" START_TIME="1440391685604" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000019" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000019_0" START_TIME="1440390284523" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000019" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391693278" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=1112087/36210" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(642695)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114237)][(MAP_OUTPUT_RECORDS)(Map output records)(36362)][(MAP_OUTPUT_BYTES)(Map output bytes)(1231764)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36362)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1313160)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(132231168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878546944)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217685)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391693470" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(642695)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114237)][(MAP_OUTPUT_RECORDS)(Map output records)(36362)][(MAP_OUTPUT_BYTES)(Map output bytes)(1231764)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36362)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1313160)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(132231168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(878546944)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71303168)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217685)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000020" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000020_0" START_TIME="1440390329571" TRACKER_NAME="tracker_vm-cluster-node1:localhost/127\.0\.0\.1:39523" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201508232259_0009_m_000020" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391688139" HOSTNAME="/default/vm-cluster-node1" STATE_STRING="Records R/W\=1098711/35749" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640680)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114166)][(MAP_OUTPUT_RECORDS)(Map output records)(36292)][(MAP_OUTPUT_BYTES)(Map output bytes)(1228452)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36292)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1323310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142159872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879579136)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217802)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000020" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391706475" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(640680)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283374)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1114166)][(MAP_OUTPUT_RECORDS)(Map output records)(36292)][(MAP_OUTPUT_BYTES)(Map output bytes)(1228452)][(SPLIT_RAW_BYTES)(Input split bytes)(110)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(36292)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1323310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(142159872)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(879579136)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(71172096)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217802)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000002" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000002_0" START_TIME="1440391685582" TRACKER_NAME="tracker_vm-cluster-node5:localhost/127\.0\.0\.1:36384" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000002" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000002_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440391706801" SORT_FINISHED="1440391706998" FINISH_TIME="1440391715133" HOSTNAME="/default/vm-cluster-node5" STATE_STRING="Records R/W\=248841/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2898844)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3070182)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(13844)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(349)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3227397)][(REDUCE_INPUT_RECORDS)(Reduce input records)(248841)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(349)][(SPILLED_RECORDS)(Spilled Records)(248841)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8550)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(119500800)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890949632)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(36438016)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_r_000002" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440391715243" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2898844)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3070182)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(13844)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(349)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3227397)][(REDUCE_INPUT_RECORDS)(Reduce input records)(248841)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(349)][(SPILLED_RECORDS)(Spilled Records)(248841)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8550)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(119500800)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(890949632)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(36438016)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000001" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000001_0" START_TIME="1440391685573" TRACKER_NAME="tracker_vm-cluster-node2:localhost/127\.0\.0\.1:57254" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000001" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000001_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440391707157" SORT_FINISHED="1440391707352" FINISH_TIME="1440391715036" HOSTNAME="/default/vm-cluster-node2" STATE_STRING="Records R/W\=245569/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2854282)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3025620)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(14385)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(364)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3167445)][(REDUCE_INPUT_RECORDS)(Reduce input records)(245569)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(364)][(SPILLED_RECORDS)(Spilled Records)(245569)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6500)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(119554048)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(892264448)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(43712512)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_r_000001" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440391715254" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(2854282)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3025620)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(14385)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(364)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3167445)][(REDUCE_INPUT_RECORDS)(Reduce input records)(245569)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(364)][(SPILLED_RECORDS)(Spilled Records)(245569)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(6500)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(119554048)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(892264448)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(43712512)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000000" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000000_0" START_TIME="1440391685572" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201508232259_0009_r_000000" TASK_ATTEMPT_ID="attempt_201508232259_0009_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1440391707077" SORT_FINISHED="1440391707303" FINISH_TIME="1440391716307" HOSTNAME="/default/vm-cluster-client" STATE_STRING="Records R/W\=271111/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(3176585)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3347925)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(14810)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(377)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3525039)][(REDUCE_INPUT_RECORDS)(Reduce input records)(271111)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(377)][(SPILLED_RECORDS)(Spilled Records)(271111)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7630)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137990144)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(894152704)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(51445760)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1440391716407" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(3176585)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(3347925)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(14810)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(377)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(3525039)][(REDUCE_INPUT_RECORDS)(Reduce input records)(271111)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(377)][(SPILLED_RECORDS)(Spilled Records)(271111)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7630)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(137990144)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(894152704)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(51445760)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000022" TASK_TYPE="CLEANUP" START_TIME="1440391716408" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201508232259_0009_m_000022" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000022_0" START_TIME="1440391716411" TRACKER_NAME="tracker_vm-cluster-client:localhost/127\.0\.0\.1:48770" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201508232259_0009_m_000022" TASK_ATTEMPT_ID="attempt_201508232259_0009_m_000022_0" TASK_STATUS="SUCCESS" FINISH_TIME="1440391718336" HOSTNAME="/default/vm-cluster-client" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171627)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(180)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108474368)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(876290048)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40435712)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201508232259_0009_m_000022" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1440391718531" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(171627)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(180)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108474368)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(876290048)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(40435712)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201508232259_0009" FINISH_TIME="1440391718532" JOB_STATUS="SUCCESS" FINISHED_MAPS="22" FINISHED_REDUCES="3" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(13697397)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2851359319)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(46)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(23650521)][(MAP_OUTPUT_RECORDS)(Map output records)(765521)][(MAP_OUTPUT_BYTES)(Map output bytes)(25915216)][(SPLIT_RAW_BYTES)(Input split bytes)(2420)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(765521)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(31385380)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(3093778432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(19400962048)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1576140800)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(2849980643)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(8929711)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(9443727)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(43039)][(HDFS_READ_OPS)(HDFS: Number of read operations)(4)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(6)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(1090)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(9919881)][(REDUCE_INPUT_RECORDS)(Reduce input records)(765521)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1090)][(SPILLED_RECORDS)(Spilled Records)(765521)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(22680)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(377044992)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(2677366784)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(131596288)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(8929711)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(23141124)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2851359319)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(43039)][(HDFS_READ_OPS)(HDFS: Number of read operations)(50)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(6)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(22)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(3)][(DATA_LOCAL_MAPS)(Data-local map tasks)(21)][(RACK_LOCAL_MAPS)(Rack-local map tasks)(1)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(35163850)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(89749)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(23650521)][(MAP_OUTPUT_RECORDS)(Map output records)(765521)][(MAP_OUTPUT_BYTES)(Map output bytes)(25915216)][(SPLIT_RAW_BYTES)(Input split bytes)(2420)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(1090)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(9919881)][(REDUCE_INPUT_RECORDS)(Reduce input records)(765521)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1090)][(SPILLED_RECORDS)(Spilled Records)(1531042)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(31408060)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(3470823424)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(22078328832)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1707737088)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(2849980643)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
